# Pipeline Apache Beam / Diplomado en Data Engineer 

**Autor:** Carlos S√°ez  

---

## Prop√≥sito del Pipeline

La **Helicopter Racing League (HRL)** es una liga internacional de carreras de helic√≥pteros que transmite sus competencias con m√©tricas de telemetr√≠a e interacci√≥n de los fans (*Fan Engagement*).  

El prop√≥sito de este pipeline es **integrar, limpiar y enriquecer** los datos de interacci√≥n provenientes de m√∫ltiples archivos **JSON**, combin√°ndolos con informaci√≥n demogr√°fica desde un archivo **CSV**, para generar un dataset final en formato **JSON Lines (.jsonl)** listo para an√°lisis o carga a un sistema de inteligencia de negocio.

---

## üóÇÔ∏è Estructura del repositorio

```
PIPELINE_APACHE_BEAM_ENTREGA1_CS/
‚îÇ
‚îú‚îÄ‚îÄ .devcontainer/                 # Configuraci√≥n del entorno en VS Code / Docker
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                 # Define la imagen base y dependencias del entorno (Python, Beam, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ devcontainer.json          # Configura VS Code para abrir el proyecto dentro del contenedor Docker
‚îÇ
‚îú‚îÄ‚îÄ input/                         # Archivos JSON (fuente principal)
‚îÇ   ‚îú‚îÄ‚îÄ cup25_fan_engagement-000-of-001.json
‚îÇ   ‚îú‚îÄ‚îÄ league04_fan_engagement-000-of-001.json
‚îÇ   ‚îî‚îÄ‚îÄ race11_fan_engagement-000-of-001.json
‚îÇ
‚îú‚îÄ‚îÄ input_side/                    # CSV auxiliar (enriquecimiento)
‚îÇ   ‚îî‚îÄ‚îÄ country_data_v2.csv
‚îÇ
‚îú‚îÄ‚îÄ output/                        # Resultado del pipeline (archivo JSONL enriquecido)
‚îÇ   ‚îî‚îÄ‚îÄ sample0-00000-of-00001.jsonl
‚îÇ
‚îú‚îÄ‚îÄ src/                           # C√≥digo fuente
‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py                # Pipeline ETL con Apache Beam
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt               # Dependencias del proyecto (Beam, pandas, etc.)
‚îî‚îÄ‚îÄ README.md                      # Documentaci√≥n e instrucciones de ejecuci√≥n

```

---

## Instrucciones para su ejecuci√≥n

### Ejecuci√≥n en DevContainer

#### **1. Requisitos previos**
- VS Code + extensi√≥n **Dev Containers** (o GitHub Codespaces).  
- **Docker Desktop** activo.  
- Clonar el repositorio:  
  ```bash
  git clone https://github.com/carlosaezp/Pipeline_Apache_Beam_Entrega1_CS.git
  ```

#### **2. Abrir el proyecto en Docker**
Al abrir la carpeta, VS Code detectar√° autom√°ticamente el entorno definido en `.devcontainer/` y mostrar√° el mensaje:  
> ‚ÄúThis workspace has a Dev Container configuration. Reopen in Container?‚Äù

Seleccionar **‚ÄúReopen in Container‚Äù**.

#### **3. Ejecutar el pipeline dentro del contenedor**
```bash
python src/pipeline.py --runner DirectRunner --output_folder output --output_prefix sample0
```

---

### Ejecuci√≥n en Google Colab

#### **1. Carga de archivos**

**Desde GitHub:**
```bash
!git clone https://github.com/carlosaezp/Pipeline_Apache_Beam_Entrega1_CS.git
```

**Desde carga local (opcional):**
```python
from google.colab import files
uploaded = files.upload()
!unzip -o "*.zip" -d /content/ > /dev/null && rm -f *.zip
```

#### **2. Ubicar carpeta**
```bash
%cd /content/Pipeline_Apache_Beam_Entrega1_CS
```

#### **3. Instalar dependencias**
```bash
!pip install -r requirements.txt
```

#### **4. Repetir pasos 2 y 3 seg√∫n entorno**

#### **5. Ejecutar pipeline**
```bash
!python src/pipeline.py --runner DirectRunner --output_folder output --output_prefix sample0
```

---

## L√≥gica de transformaci√≥n

El pipeline implementa un flujo **ETL (Extract ‚Äì Transform ‚Äì Load)** con **Apache Beam**, para limpiar, estandarizar y enriquecer los datos de interacci√≥n de los fans de la HRL.

### **1. Extracci√≥n**
- Lectura de m√∫ltiples archivos JSON con m√©tricas de interacci√≥n.  
- Lectura de un archivo CSV con informaci√≥n de pa√≠ses.

### **2. Estandarizaci√≥n**
- Normalizaci√≥n del campo `RaceID` al formato `<string><n√∫mero>` (ejemplo: *Cup 25 ‚Üí cup25*).  
- Eliminaci√≥n de registros donde `DeviceType` sea `"Other"`.

### **3. Enriquecimiento**
- Uni√≥n de cada registro JSON con la informaci√≥n del CSV seg√∫n el campo `ViewerLocationCountry`.  
- Creaci√≥n de una estructura anidada `LocationData` con los campos:
  - `country`  
  - `capital`  
  - `continent`  
  - `official_language`  
  - `currency`

### **4. Proyecci√≥n**
- Reorganizaci√≥n de columnas, manteniendo solo las necesarias para el esquema final.  
- Eliminaci√≥n de campos redundantes o irrelevantes.

### **5. Carga (Load)**
- Escritura del resultado en formato **JSON Lines (.jsonl)** dentro de `output/`.  
- Cada l√≠nea representa un registro completo y enriquecido, compatible con herramientas como **BigQuery**, **Athena** y **pandas**.

---

## Resultado final

El pipeline genera el archivo:

```
output/sample0-00000-of-00001.jsonl
```

El cual contiene la informaci√≥n enriquecida y estandarizada, lista para an√°lisis o integraci√≥n en una plataforma de visualizaci√≥n o Data Warehouse.
